---
title: "Using Characterization Package"
author: "Jenna Reps"
date: '`r Sys.Date()`'
header-includes:
    - \usepackage{fancyhdr}
    - \pagestyle{fancy}
    - \fancyhead{}
    - \fancyhead[CO,CE]{Installation Guide}
    - \fancyfoot[CO,CE]{Characterization Package Version `r    utils::packageVersion("Characterization")`}
    - \fancyfoot[LE,RO]{\thepage}
    - \renewcommand{\headrulewidth}{0.4pt}
    - \renewcommand{\footrulewidth}{0.4pt}
output:
  pdf_document:
    includes:
      in_header: preamble.tex
    number_sections: yes
    toc: yes
  word_document:
    toc: yes
  html_document:
    number_sections: yes
    toc: yes
---
<!--
%\VignetteEngine{knitr}
%\VignetteIndexEntry{Installation guide}
-->

# Introduction
This vignette describes how you can use the Characterization package for various descriptive studies using OMOP CDM data. The Characterization package currently contains three different types of analyses:

- Aggreagate Covariates: this returns the mean feature value for a set of features specified by the user for i) the Target cohort population, ii) the Outcome cohort population, iii) the Target population patients who had the outcome during some user specified time-at-risk and iv) the Target population patients who did not have the outcome during some user specified time-at-risk.
- DechallengeRechallenge: this is mainly aimed at investigating whether a drug and event are causally related by seeing whether the drug is stopped close in time to the event occurrence (dechallenge) and then whether the drug is restarted (a rechallenge occurs) and if so, whether the event starts again (a failed rechallenge). In this analysis, the Target cohorts are the drug users of interest and the Outcome cohorts are the medical events you wish to see whether the drug may cause.  The user must also specify how close in time a drug msut be stopped after the outcome to be considered a dechallenge and how close in time an Outcome must occur after restarting the drug to be considered a failed rechallenge).
- Time-to-event: this returns descriptive results showing the timing between the target cohort and outcome.  This can help identify whether the outcome often precedes the target cohort or whether it generally comes after.

# Setup

In this vignette we will show working examples using the `Eunomia` R package that contains simulated data.  Run the following code to install the `Eunomia` R package:

```{r tidy=TRUE,eval=FALSE}
install.packages('remotes')
remotes::install_github('ohdsi/Eunomia')
```

Eunomia can be used to create a temporary SQLITE database with the simulated data.  The function `getEunomiaConnectionDetails` creates a SQLITE connection to a temporary location. The function `createCohorts` then populates the temporary SQLITE database with the simulated data ready to be used.

```{r tidy=TRUE,eval=TRUE}
connectionDetails <- Eunomia::getEunomiaConnectionDetails()
Eunomia::createCohorts(connectionDetails = connectionDetails)
```

We also need to have the Characterization package installed and loaded
```{r tidy=TRUE,eval=FALSE}
remotes::install_github('ohdsi/FeatureExtraction')
remotes::install_github('ohdsi/Characterization')
```

```{r tidy=TRUE,eval=TRUE}
library(Characterization)
library(dplyr)
```

# Examples 
## Aggreagate Covariates

To run an 'Aggregate Covariate' analysis you need to create a setting object using `createAggregateCovariateSettings`.  This requires specifying:

- one or more targetIds (these must be pre-generated in a cohort table)
- one or more outcomeIds (these must be pre-generated in a cohort table)
- the covariate settings using `FeatureExtraction::createCovariateSettings` or by creating your own custom feature extraction code.
- the time-at-risk settings
+ riskWindowStart
+ startAnchor
+ riskWindowEnd
+ endAnchor

Using the Eunomia data were we previous generated four cohorts, we can use cohort ids 1,2 and 4 as the targetIds and cohort id 3 as the outcomeIds:  

```{r eval=TRUE}
  exampleTargetIds <- c(1,2,4)
  exampleOutcomeIds <- 3
```

If we want to get information on the sex assigned at birth, age at index and Charlson Comorbidity index we can create the settings using `FeatureExtraction::createCovariateSettings`:

```{r eval=TRUE}
  exampleCovariateSettings <- FeatureExtraction::createCovariateSettings(
    useDemographicsGender = T,
    useDemographicsAge = T,
    useCharlsonIndex = T
    )
```

If we want to create the aggregate features for all our target cohorts, our outcome cohort and each target cohort restricted to those with a record of the outcome 1 day after target cohort start date until 365 days after target cohort end date we can run:

```{r eval=TRUE}
  exampleAggregateCovariateSettings <- createAggregateCovariateSettings(
    targetIds = exampleTargetIds,
    outcomeIds = exampleOutcomeIds,
    riskWindowStart = 1, startAnchor = 'cohort start',
    riskWindowEnd = 365, endAnchor = 'cohort start',
    covariateSettings = exampleCovariateSettings
    )
```

Next we need to use the `exampleAggregateCovariateSettings` as the settings to `computeAggregateCovariateAnalyses`, we need to use the Eunomia connectionDetails and in Eunomia the OMOP CDM data and cohort table are in the 'main' schema.  The cohort table name is 'cohort'.  The following code will apply the aggregative covariates analysis using the previously specified settings on the simulated Eunomia data:

```{r eval=TRUE,results='hide',error=FALSE,warning=FALSE,message=FALSE}
agc <- computeAggregateCovariateAnalyses(
    connectionDetails = connectionDetails,
    cdmDatabaseSchema = 'main',
    cdmVersion = 5,
    targetDatabaseSchema = 'main',
    targetTable = 'cohort',
    aggregateCovariateSettings = exampleAggregateCovariateSettings,
    databaseId = 'Eunomia', 
    runId = 1
    )
```

If you would like to save the results you can use the function `saveAggregateCovariateAnalyses` and this can then be loaded using `loadAggregateCovariateAnalyses`.

The results are Andromeda objects that can we viewed using `dplyr`.  There are four tables:
 
- covariates:
```{r eval=TRUE}
agc$covariates %>% 
  collect() %>%
  kableExtra::kbl() 
```

- covariatesContinuous:
```{r eval=TRUE}
agc$covariatesContinuous %>% 
  collect() %>%
  kableExtra::kbl() 
```

- covariateRef:
```{r eval=TRUE}
agc$covariateRef %>% 
  collect() %>%
  kableExtra::kbl() 
```

- analysisRef:
```{r eval=TRUE}
agc$analysisRef %>% 
  collect() %>%
  kableExtra::kbl() 
```

## Dechallenge Rechallenge

To run a 'Dechallenge Rechallenge' analysis you need to create a setting object using `createDechallengeRechallengeSettings`.  This requires specifying:

- one or more targetIds (these must be pre-generated in a cohort table)
- one or more outcomeIds (these must be pre-generated in a cohort table)
- dechallengeStopInterval
- dechallengeEvaluationWindow

Using the Eunomia data were we previous generated four cohorts, we can use cohort ids 1,2 and 4 as the targetIds and cohort id 3 as the outcomeIds:  

```{r eval=TRUE}
  exampleTargetIds <- c(1,2,4)
  exampleOutcomeIds <- 3
```

If we want to create the dechallenge rechallenge for all our target cohorts and our outcome cohort with a 30 day dechallengeStopInterval and 31 day dechallengeEvaluationWindow:

```{r eval=TRUE}
  exampleDechallengeRechallengeSettings <- createDechallengeRechallengeSettings(
    targetIds = exampleTargetIds,
    outcomeIds = exampleOutcomeIds,
    dechallengeStopInterval = 30,
    dechallengeEvaluationWindow = 31
    )
```

We can then run  the analysis on the Eunomia data using `computeDechallengeRechallengeAnalyses` and the settings previously specified:

```{r eval=TRUE}
dc <- computeDechallengeRechallengeAnalyses(
    connectionDetails = connectionDetails,
    targetDatabaseSchema = 'main',
    targetTable = 'cohort',
    dechallengeRechallengeSettings = exampleDechallengeRechallengeSettings,
    databaseId = 'Eunomia'
    )
```

If you would like to save the results you can use the function `saveDechallengeRechallengeAnalyses` and this can then be loaded using `loadDechallengeRechallengeAnalyses`.

The results are Andromeda objects that can we viewed using `dplyr`.  There is just one table named dechallengeRechallenge:
 
```{r eval=TRUE}
dc$dechallengeRechallenge %>% 
  collect() %>%
  kableExtra::kbl() 
```

Next it is possible to computer and extract the failed rechallenge cases

```{r eval=TRUE}
failed <- computeRechallengeFailCaseSeriesAnalyses(
  connectionDetails = connectionDetails,
  targetDatabaseSchema = 'main',
  targetTable = 'cohort',
  dechallengeRechallengeSettings = exampleDechallengeRechallengeSettings,
  outcomeDatabaseSchema = 'main',
  outcomeTable = 'cohort',
  databaseId = 'Eunomia'
)
```

The results are Andromeda objects that can we viewed using `dplyr`.  There is just one table named rechallengeFailCaseSeries:
 
```{r eval=TRUE}
failed$rechallengeFailCaseSeries %>% 
  collect() %>%
  kableExtra::kbl() 
```

## Time to Event

To run a 'Time-to-event' analysis you need to create a setting object using `createTimeToEventSettings`.  This requires specifying:

- one or more targetIds (these must be pre-generated in a cohort table)
- one or more outcomeIds (these must be pre-generated in a cohort table)

```{r eval=TRUE}
  exampleTimeToEventSettings <- createTimeToEventSettings(
    targetIds = exampleTargetIds,
    outcomeIds = exampleOutcomeIds
    )
```

We can then run  the analysis on the Eunomia data using `computeTimeToEventAnalyses` and the settings previously specified:

```{r eval=TRUE}
tte <- computeTimeToEventAnalyses(
    connectionDetails = connectionDetails,
    cdmDatabaseSchema = 'main',
    targetDatabaseSchema = 'main',
    targetTable = 'cohort', 
    timeToEventSettings =  exampleTimeToEventSettings,
    databaseId = 'Eunomia'
    )
```

If you would like to save the results you can use the function `saveTimeToEventAnalyses` and this can then be loaded using `loadTimeToEventAnalyses`.

The results are Andromeda objects that can we viewed using `dplyr`.  There is just one table named timeToEvent:
 
```{r eval=TRUE}
tte$timeToEvent %>% 
  collect() %>%
  top_n(10) %>%
  kableExtra::kbl() 
```


## Run Multiple 

If you want to run multiple analyses (of the three previously shown) you can use `createCharacterizationSettings`.  You need to input a list of each of the settings (or NULL if you do not want to run one type of analysis).  To run all the analyses previously shown in one function:

```{r eval=FALSE,results='hide',error=FALSE,warning=FALSE,message=FALSE}
  characterizationSettings <- createCharacterizationSettings(
    timeToEventSettings = list(
      exampleTimeToEventSettings
      ),
    dechallengeRechallengeSettings = list(
      exampleDechallengeRechallengeSettings
    ),
    aggregateCovariateSettings = list(
      exampleAggregateCovariateSettings
      )
  )

# save the settings using
saveCharacterizationSettings(
  settings = characterizationSettings, 
  saveDirectory = file.path(tempdir(), 'saveSettings')
    )

# the settings can be loaded
characterizationSettings <- loadCharacterizationSettings(
  saveDirectory = file.path(tempdir(), 'saveSettings')
    )

runCharacterizationAnalyses(
  connectionDetails = connectionDetails,
  cdmDatabaseSchema = 'main',
  targetDatabaseSchema = 'main',
  targetTable = 'cohort',
  outcomeDatabaseSchema = 'main',
  outcomeTable = 'cohort',
  characterizationSettings = characterizationSettings,
  saveDirectory = file.path(tempdir(), 'example'),
  tablePrefix = 'c_',
  databaseId = '1'
)

```

This will create an SQLITE database with all the analyses saved into the saveDirectory.  You can export the results as csv files using:

```{r eval=FALSE}
connectionDetailsT <- DatabaseConnector::createConnectionDetails(
  dbms = 'sqlite',
  server = file.path(tempdir(),'example','sqliteCharacterization', 'sqlite')
)

exportDatabaseToCsv(
  connectionDetails = connectionDetailsT,
  resultSchema = 'main',
  targetDialect = 'sqlite',
  tablePrefix = 'c_',
  saveDirectory = file.path(tempdir(),'csv')
)
```
